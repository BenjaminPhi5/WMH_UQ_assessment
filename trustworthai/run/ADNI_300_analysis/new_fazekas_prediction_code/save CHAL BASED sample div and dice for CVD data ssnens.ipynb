{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f64cd201-3332-41bd-bf9a-f9e72526f963",
   "metadata": {},
   "source": [
    "### Load Model Samples\n",
    "save dice:\n",
    "dice is based on SSN Ens Mean I think? or SSN Ens? I am not sure....?\n",
    "sample diversity definately comes from SSN Ens.\n",
    "I am not sure how much memory I need for this aha\n",
    "Sample diversity should be based on AVD and I should check the mean dice against what I have reported in my paper (it should be similar, probs won't be exactly the same)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6aa71d21-3a35-4705-9d97-2718edcd5701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strawberry\n",
      "banana\n"
     ]
    }
   ],
   "source": [
    "print(\"strawberry\")\n",
    "\n",
    "# loss function and metrics\n",
    "from trustworthai.utils.losses_and_metrics.dice_loss import DiceLossWithWeightedEmptySlices\n",
    "from trustworthai.utils.losses_and_metrics.dice_loss_metric import DiceLossMetric, SsnDiceMeanMetricWrapper\n",
    "\n",
    "# predefined training dataset\n",
    "from trustworthai.utils.data_preprep.dataset_pipelines import load_data\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "# fitter\n",
    "from trustworthai.utils.fitting_and_inference.fitters.basic_lightning_fitter import StandardLitModelWrapper\n",
    "from trustworthai.utils.fitting_and_inference.fitters.p_unet_fitter import PUNetLitModelWrapper\n",
    "from trustworthai.utils.fitting_and_inference.get_trainer import get_trainer\n",
    "\n",
    "# model\n",
    "from trustworthai.run.model_load.load_ssn import load_ssn\n",
    "from trustworthai.run.model_load.load_punet import load_p_unet\n",
    "from trustworthai.run.model_load.load_deterministic import load_deterministic\n",
    "from trustworthai.models.stochastic_wrappers.ssn.LowRankMVCustom import LowRankMultivariateNormalCustom\n",
    "from trustworthai.models.stochastic_wrappers.ssn.ReshapedDistribution import ReshapedDistribution\n",
    "\n",
    "# optimizer and lr scheduler\n",
    "import torch\n",
    "\n",
    "# misc\n",
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import shlex\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "from natsort import natsorted\n",
    "\n",
    "print(\"banana\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3561b57-8ba3-4fbc-b5f1-374837faa575",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trustworthai.utils.data_preprep.dataset_pipelines import load_clinscores_data, load_data, ClinScoreDataRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a1343b8-a9a8-40ac-a68b-f895588c9a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_folder = \"/home/s2208943/ipdis/results/cross_validated_models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75c3060c-304f-4a17-98cc-7e9c4b19282e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_parser():\n",
    "    parser = argparse.ArgumentParser(description = \"train models\")\n",
    "    \n",
    "    # folder arguments\n",
    "    parser.add_argument('--ckpt_dir', default='s2208943/results/revamped_models/', type=str)\n",
    "    parser.add_argument('--model_name', default=None, type=str)\n",
    "    \n",
    "    # data generation arguments\n",
    "    parser.add_argument('--dataset', default='ed', type=str)\n",
    "    parser.add_argument('--seed', default=3407, type=int)\n",
    "    parser.add_argument('--test_split', default=0.15, type=float)\n",
    "    parser.add_argument('--val_split', default=0.15, type=float)\n",
    "    parser.add_argument('--empty_slice_retention', default=0.1, type=float)\n",
    "    \n",
    "    # model specific parameters SSN\n",
    "    parser.add_argument('--ssn_rank', default=15, type=int)\n",
    "    parser.add_argument('--ssn_epsilon', default=1e-5, type=float)\n",
    "    parser.add_argument('--ssn_mc_samples', default=10, type=int)\n",
    "    parser.add_argument('--ssn_sample_dice_coeff', default=0.05, type=float)\n",
    "    parser.add_argument('--ssn_pre_head_layers', default=16, type=int)\n",
    "    \n",
    "    # evidential loss parameters\n",
    "    parser.add_argument('--kl_factor', default=0.1, type=float)\n",
    "    parser.add_argument('--kl_anneal_count', default=452*4, type=int)\n",
    "    \n",
    "     # model specific parameters Punet\n",
    "    parser.add_argument('--kl_beta', default=10.0, type=float)\n",
    "    parser.add_argument('--use_prior_for_dice', default=False, type=bool)\n",
    "    parser.add_argument('--punet_sample_dice_coeff', default=0.05, type=float)\n",
    "    parser.add_argument('--latent_dim', default=12, type=int)\n",
    "    \n",
    "    # general arguments for the loss function\n",
    "    parser.add_argument('--dice_factor', default=5, type=float)\n",
    "    parser.add_argument('--xent_factor', default=0.01, type=float)\n",
    "    parser.add_argument('--dice_empty_slice_weight', default=0.5, type=float)\n",
    "    \n",
    "    # general arguments for the loss function\n",
    "    parser.add_argument('--loss_name', default='dice+xent', type=str)\n",
    "    # parser.add_argument('--dice_factor', default=5, type=float)\n",
    "    # parser.add_argument('--xent_factor', default=0.01, type=float)\n",
    "    parser.add_argument('--xent_weight', default='none', type=str)\n",
    "    #parser.add_argument('--dice_empty_slice_weight', default=0.5, type=float)\n",
    "    parser.add_argument('--tversky_beta', default=0.7, type=float)\n",
    "    parser.add_argument('--reduction', default='mean_sum', type=str)\n",
    "    \n",
    "    # training paradigm arguments\n",
    "    parser.add_argument('--lr', default=2e-4, type=float)\n",
    "    parser.add_argument('--dropout_p', default=0.0, type=float)\n",
    "    parser.add_argument('--max_epochs', default=100, type=int)\n",
    "    parser.add_argument('--early_stop_patience', default=15, type=int)\n",
    "    parser.add_argument('--batch_size', default=32, type=int)\n",
    "    parser.add_argument('--cross_validate', default=False, type=bool)\n",
    "    parser.add_argument('--cv_split', default=0, type=int)\n",
    "    parser.add_argument('--cv_test_fold_smooth', default=1, type=int)\n",
    "    parser.add_argument('--weight_decay', default=0.0001, type=float)\n",
    "    parser.add_argument('--overwrite', default=False, type=bool)\n",
    "    \n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4adbac25-a469-4bb1-9eb5-7095d1d03c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_best_checkpoint(model, loss, model_ckpt_folder, punet=False):\n",
    "    # this is ultimately going to need to be passed a model wrapper when I implement P-Unet....\n",
    "    \n",
    "    # the path to the best checkpoint is stored as a single line in a txt file along with each model\n",
    "    with open(os.path.join(model_ckpt_folder, \"best_ckpt.txt\"), \"r\") as f:\n",
    "        ckpt_file = os.path.join(model_ckpt_folder, f.readlines()[0][:-1].split(\"/\")[-1])\n",
    "    \n",
    "    if punet:\n",
    "        return PUNetLitModelWrapper.load_from_checkpoint(ckpt_file, model=model, loss=loss, \n",
    "                                    logging_metric=lambda : None)\n",
    "    return StandardLitModelWrapper.load_from_checkpoint(ckpt_file, model=model, loss=loss, \n",
    "                                    logging_metric=lambda : None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0baae5f6-42bf-4a39-aaf5-8cac2d7a9210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_map_from_mean(mean, do_normalize=True):\n",
    "    \"samples is of shape samples, batch size, channels, image dims  [s, b, c *<dims>]\"\n",
    "    if mean.shape[1] == 1:\n",
    "        raise ValueError(\"not implemented for implicit background class\")\n",
    "    else:\n",
    "        assert mean.shape[1] == 2\n",
    "    \n",
    "    if do_normalize:\n",
    "        probs = torch.nn.functional.softmax(mean, dim=1)\n",
    "    else:\n",
    "        probs = mean\n",
    "    ent_map = torch.sum(-probs * torch.log(probs+1e-30), dim=1)\n",
    "\n",
    "    return ent_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "598f5d3b-2b60-4ce6-8918-f0d706b46631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_means_and_samples_SSN(splits=6, dataset_stride=2, temp=1, num_samples=10, use_updated_scores=False):\n",
    "    # load data\n",
    "    clin_retriever = ClinScoreDataRetriever(use_updated_scores=use_updated_scores)\n",
    "    \n",
    "    rank = 15\n",
    "    \n",
    "    # load model\n",
    "    class TestArgs():\n",
    "        def __init__(self, ):\n",
    "            args_dict = {\n",
    "                \"dropout_p\":0,\n",
    "                \"ssn_pre_head_layers\":32,\n",
    "                \"ssn_rank\":rank,\n",
    "                \"ssn_epsilon\":1e-5,\n",
    "                \"dice_empty_slice_weight\":0.5,\n",
    "                \"ssn_mc_samples\":10,\n",
    "                \"dice_factor\":5,\n",
    "                \"xent_factor\":0.01,\n",
    "                \"ssn_sample_dice_coeff\":0.05\n",
    "            }\n",
    "\n",
    "            for key, value in args_dict.items():\n",
    "                setattr(self, key, value)\n",
    "\n",
    "    args = TestArgs()\n",
    "\n",
    "    model_raw, loss = load_ssn(args)\n",
    "    model_raw = model_raw.cuda()\n",
    "    \n",
    "    models_folder = \"/home/s2208943/ipdis/results/cross_validated_models/\"\n",
    "    #model_names = os.listdir(models_folder)\n",
    "\n",
    "    model_base_name = \"ssn_WMH_chal\"\n",
    "    ensemble_element = 1\n",
    "\n",
    "    means = []\n",
    "    samples = []\n",
    "\n",
    "    test_datasets = []\n",
    "\n",
    "    for split in range(splits):\n",
    "        \n",
    "        # load specific data split\n",
    "        train_ds_clin, val_ds_clin, test_ds_clin = clin_retriever.load_clinscores_data(\n",
    "            combine_all=False,\n",
    "            test_proportion=0.15, \n",
    "            validation_proportion=0.15,\n",
    "            seed=3407,\n",
    "            cross_validate=True,\n",
    "            cv_split=split,\n",
    "            cv_test_fold_smooth=1,\n",
    "            \n",
    "        )\n",
    "        test_datasets.append(test_ds_clin)\n",
    "        print(\"size: \", len(test_ds_clin))\n",
    "\n",
    "\n",
    "        for ens in range(1):\n",
    "            model_name = model_base_name + f\"_ens{ensemble_element}/\"\n",
    "            model_path = models_folder + model_name\n",
    "\n",
    "            model = load_best_checkpoint(model_raw, loss, model_path)\n",
    "            model.eval()\n",
    "\n",
    "\n",
    "            dataskip = dataset_stride\n",
    "            \n",
    "        for i, data in enumerate(tqdm(test_ds_clin, position=0, leave=True)):\n",
    "            if i % dataskip == 0:\n",
    "                x = data[0]\n",
    "                with torch.no_grad():\n",
    "                    mean, sample = model.mean_and_sample(x.swapaxes(0,1).cuda(), num_samples=num_samples, temperature=temp)\n",
    "                    means.append(mean.cpu())\n",
    "                    samples.append(sample.cpu())\n",
    "\n",
    "    return means, samples, ConcatDataset(test_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd1a7915-2419-4737-85bf-f8f4da925f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_means_and_samples_SSN_Ens_Efficient(splits=6, dataset_stride=2, temp=1, num_samples=10, use_updated_scores=False, ensemble_size=6):\n",
    "    # load data\n",
    "    clin_retriever = ClinScoreDataRetriever(use_updated_scores=use_updated_scores)\n",
    "    \n",
    "    # load model\n",
    "    class TestArgs():\n",
    "        def __init__(self, ):\n",
    "            args_dict = {\n",
    "                \"dropout_p\":0,\n",
    "                \"ssn_pre_head_layers\":32,\n",
    "                \"ssn_rank\":15,\n",
    "                \"ssn_epsilon\":1e-5,\n",
    "                \"dice_empty_slice_weight\":0.5,\n",
    "                \"ssn_mc_samples\":10,\n",
    "                \"dice_factor\":5,\n",
    "                \"xent_factor\":0.01,\n",
    "                \"ssn_sample_dice_coeff\":0.05\n",
    "            }\n",
    "\n",
    "            for key, value in args_dict.items():\n",
    "                setattr(self, key, value)\n",
    "\n",
    "    args = TestArgs()\n",
    "\n",
    "    model_raw, loss = load_ssn(args)\n",
    "    model_raw = model_raw.cuda()\n",
    "    \n",
    "    models_folder = \"/home/s2208943/ipdis/results/cross_validated_models/\"\n",
    "    #model_names = os.listdir(models_folder)\n",
    "\n",
    "    model_base_name = \"ssn_WMH_chal\"\n",
    "\n",
    "    means = []\n",
    "    samples = []\n",
    "\n",
    "    test_datasets = []\n",
    "\n",
    "    for split in range(splits):\n",
    "        model_outs = defaultdict(lambda : {'means':[], 'samples':[]})\n",
    "        \n",
    "        # load specific data split\n",
    "        train_ds_clin, val_ds_clin, test_ds_clin = clin_retriever.load_clinscores_data(\n",
    "            combine_all=False,\n",
    "            test_proportion=0.15, \n",
    "            validation_proportion=0.15,\n",
    "            seed=3407,\n",
    "            cross_validate=True,\n",
    "            cv_split=split,\n",
    "            cv_test_fold_smooth=1,\n",
    "            \n",
    "        )\n",
    "        test_datasets.append(test_ds_clin)\n",
    "        print(\"size: \", len(test_ds_clin))\n",
    "\n",
    "\n",
    "        for ens in range(ensemble_size):\n",
    "            model_name = model_base_name + f\"_ens{ens}/\"\n",
    "            model_path = models_folder + model_name\n",
    "\n",
    "            # with open(model_path + \"best_ckpt.txt\") as f:\n",
    "            #     lines = f.readlines()\n",
    "            #     args_lines = [l[:-1].split(\": \") for l in lines[1:]]\n",
    "            #     args_lines = [f'--{l[0]} {l[1]}' for l in args_lines]\n",
    "            #     args_line = \" \".join(args_lines)\n",
    "            #     parser = construct_parser()\n",
    "            #     args = parser.parse_args(shlex.split(args_line))\n",
    "\n",
    "            # load the model\n",
    "            model = load_best_checkpoint(model_raw, loss, model_path)\n",
    "            model.eval()\n",
    "\n",
    "\n",
    "            dataskip = dataset_stride\n",
    "            # means = []\n",
    "            # samples = []\n",
    "            for i, data in enumerate(tqdm(test_ds_clin, position=0, leave=True)):\n",
    "                if i % dataskip == 0:\n",
    "                    x = data[0]\n",
    "                    with torch.no_grad():\n",
    "                        mean, sample = model.mean_and_sample(x.swapaxes(0,1).cuda(), num_samples=num_samples, temperature=temp, symmetric=False)\n",
    "\n",
    "                        model_outs[i]['means'].append(mean.cpu())\n",
    "                        model_outs[i]['samples'].append(sample.cpu())\n",
    "\n",
    "        for idx in tqdm(model_outs.keys(), position=0, leave=True):\n",
    "            means.append(torch.stack(model_outs[idx]['means'], dim=0).mean(dim=0))\n",
    "            samples.append(torch.cat(model_outs[idx]['samples'], dim=0))\n",
    "\n",
    "    return means, samples, ConcatDataset(test_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd45e6b9-9ad2-4c56-9282-9fee523fdacf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_means_and_samples_SSN_Ens_Mean(splits=6, dataset_stride=2, temp=1, num_samples=10, use_updated_scores=False, ensemble_size=6):\n",
    "    components = ensemble_size\n",
    "    # load data\n",
    "    print(\"loading\")\n",
    "    clin_retriever = ClinScoreDataRetriever(use_updated_scores=use_updated_scores)\n",
    "    print(\"loaded\")\n",
    "    \n",
    "    test_datasets = []\n",
    "\n",
    "    # load model\n",
    "    class TestArgs():\n",
    "        def __init__(self, ):\n",
    "            args_dict = {\n",
    "                \"dropout_p\":0,\n",
    "                \"ssn_pre_head_layers\":32,\n",
    "                \"ssn_rank\":15,\n",
    "                \"ssn_epsilon\":1e-5,\n",
    "                \"dice_empty_slice_weight\":0.5,\n",
    "                \"ssn_mc_samples\":10,\n",
    "                \"dice_factor\":5,\n",
    "                \"xent_factor\":0.01,\n",
    "                \"ssn_sample_dice_coeff\":0.05\n",
    "            }\n",
    "\n",
    "            for key, value in args_dict.items():\n",
    "                setattr(self, key, value)\n",
    "\n",
    "    args = TestArgs()\n",
    "\n",
    "    model_raw, loss = load_ssn(args)\n",
    "    model_raw = model_raw.cuda()\n",
    "    model_raw.return_cpu_dist = True\n",
    "\n",
    "    models_folder = \"/home/s2208943/ipdis/results/cross_validated_models/\"\n",
    "    #model_names = os.listdir(models_folder)\n",
    "\n",
    "    model_base_name = \"ssn_WMH_chal\"\n",
    "\n",
    "    means = []\n",
    "    samples = []\n",
    "\n",
    "    for split in range(splits):\n",
    "        # load specific data split\n",
    "        train_ds_clin, val_ds_clin, test_ds_clin = clin_retriever.load_clinscores_data(\n",
    "            combine_all=False,\n",
    "            test_proportion=0.15, \n",
    "            validation_proportion=0.12,\n",
    "            seed=3407,\n",
    "            cross_validate=True,\n",
    "            cv_split=split,\n",
    "            cv_test_fold_smooth=1,\n",
    "        )\n",
    "        test_datasets.append(test_ds_clin)\n",
    "        # print(\"size: \", len(test_ds_clin))\n",
    "\n",
    "        dataskip = dataset_stride\n",
    "\n",
    "        for i, data in enumerate(tqdm(test_ds_clin, position=0, leave=True)):\n",
    "            if i % dataskip == 0:\n",
    "                x = data[0].swapaxes(0,1).cuda()\n",
    "                distribution_means = []\n",
    "                distribution_cov_diags = []\n",
    "                distribution_cov_factors = []\n",
    "                distribution_event_shapes = []\n",
    "\n",
    "                for ens in range(components):\n",
    "                    # print(ens)\n",
    "                    model_name = model_base_name + f\"_ens{ens}/\"\n",
    "                    model_path = models_folder + model_name\n",
    "                    model = load_best_checkpoint(model_raw, loss, model_path)\n",
    "                    model.eval()\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        mean, cov_diag, cov_factor, event_shape = model(x)\n",
    "                    distribution_means.append(mean.cpu())\n",
    "                    distribution_cov_diags.append(cov_diag.cpu())\n",
    "                    distribution_cov_factors.append(cov_factor.cpu())\n",
    "                    distribution_event_shapes.append(event_shape)\n",
    "\n",
    "                # print(distribution_means[0].shape)\n",
    "\n",
    "                distribution_means = torch.stack(distribution_means, dim=0).mean(dim=0)\n",
    "                distribution_cov_diags = torch.stack(distribution_cov_diags, dim=0).mean(dim=0)\n",
    "                distribution_cov_factors = torch.stack(distribution_cov_factors, dim=0).mean(dim=0)\n",
    "\n",
    "                # print(distribution_means.shape)\n",
    "\n",
    "                dist = LowRankMultivariateNormalCustom(distribution_means, distribution_cov_factors, distribution_cov_diags)\n",
    "                dist = ReshapedDistribution(dist, distribution_event_shapes[0])\n",
    "\n",
    "                means.append((dist.mean / temp).cpu())\n",
    "                samples.append((model_raw._samples_from_dist(dist, num_samples=num_samples)/temp).cpu())\n",
    "\n",
    "    return means, samples, ConcatDataset(test_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4731c404-dce9-46b9-a4c5-f93f90d6a230",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from trustworthai.utils.uncertainty_maps.entropy_map import entropy_map_from_samples\n",
    "from trustworthai.utils.plotting.saving_plots import save, imsave\n",
    "from trustworthai.utils.print_and_write_func import print_and_write\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d84d4b30-19af-4747-9d9b-8359b42f089f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#samples[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1aa8527-7263-4c05-8505-215f7a7b468d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stride = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f879a8e-40da-46d2-a73d-58aad39c2d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size:  42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:16<00:00,  2.61it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:12<00:00,  3.35it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:12<00:00,  3.34it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:12<00:00,  3.34it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:12<00:00,  3.32it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:12<00:00,  3.31it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:02<00:00, 18.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size:  42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:11<00:00,  3.71it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:12<00:00,  3.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:12<00:00,  3.28it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:12<00:00,  3.28it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:12<00:00,  3.29it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:12<00:00,  3.29it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:02<00:00, 15.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size:  42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:11<00:00,  3.70it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:11<00:00,  3.67it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:11<00:00,  3.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:11<00:00,  3.64it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:11<00:00,  3.64it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:12<00:00,  3.45it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:03<00:00, 11.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size:  42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:11<00:00,  3.70it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:11<00:00,  3.70it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:11<00:00,  3.57it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:12<00:00,  3.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:12<00:00,  3.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:12<00:00,  3.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:05<00:00,  7.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size:  42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:11<00:00,  3.70it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:11<00:00,  3.71it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:11<00:00,  3.60it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:12<00:00,  3.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:12<00:00,  3.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:12<00:00,  3.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:05<00:00,  7.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size:  40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:11<00:00,  3.52it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:11<00:00,  3.37it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:11<00:00,  3.38it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:11<00:00,  3.38it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:11<00:00,  3.38it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:11<00:00,  3.38it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:05<00:00,  7.96it/s]\n"
     ]
    }
   ],
   "source": [
    "# means, samples, test_datasets = generate_means_and_samples_SSN(splits=6, dataset_stride=stride, temp=1, num_samples=10)\n",
    "means, samples, test_datasets = generate_means_and_samples_SSN_Ens_Efficient(splits=6, dataset_stride=stride, temp=1, num_samples=2, use_updated_scores=False)\n",
    "# means, samples, test_datasets = generate_means_and_samples_SSN_Ens_Mean(splits=6, dataset_stride=stride, temp=1, num_samples=10, use_updated_scores=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd26c099-11c4-46d1-94f7-c8a2eb68e8bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 250)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(means), len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fb9188-d9bb-43e1-b631-bb175f7951ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff10b600-671d-4b56-8b7e-1266b4b64281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax entropy\n",
    "# ent_maps = [entropy_map_from_mean(means[scan_index], do_normalize=True) for scan_index in range(len(means))]\n",
    "\n",
    "# evidential\n",
    "# ent_maps = [entropy_map_from_mean(means[scan_index], do_normalize=False) for scan_index in range(len(means))]\n",
    "\n",
    "# other methods\n",
    "ent_maps = [entropy_map_from_samples(samples[scan_index]) for scan_index in range(len(means))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8e0afe9-aa93-4432-bd4c-f51c3db91279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 159.5, 223.5, -0.5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scan_id = 0\n",
    "islice = 20\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(ent_maps[scan_id][islice]); plt.axis('off')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(means[scan_id][islice].argmax(dim=0)); plt.axis('off')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(test_datasets[scan_id][1][0][islice]); plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87c03edf-4939-49ae-826b-e9276d4e9c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_dice(pred, target):\n",
    "    p1 = (pred == 1)\n",
    "    t1 = (target == 1)\n",
    "    intersection = (pred == 1) & (target == 1)\n",
    "    numerator = 2 * intersection.sum()\n",
    "    denominator = p1.sum() + t1.sum()\n",
    "    return (numerator/(denominator + 1e-30)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b3079d0-fac7-4b03-aaf0-b9557dd17906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 2, 224, 160])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4f05076-ae8a-444f-8e9f-87ae7e064f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:03<00:00, 81.36it/s]\n"
     ]
    }
   ],
   "source": [
    "dices = []\n",
    "for i in tqdm(range(len(means)), position=0, leave=True):\n",
    "    pred = means[i].cuda().argmax(dim=1)\n",
    "    target = test_datasets[i][1][0].cuda()\n",
    "    dices.append(fast_dice(pred, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34eec10b-8347-4aee-957d-497968e3a50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_dices = [d for d in dices if d > 0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da9dc4c9-eb6c-40d1-a765-0d8e4283ce80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5605)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(f_dices).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb6c5a1e-288e-4f84-9d73-6a214678d573",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDs = [data[2]['ID'] for data in test_datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13bc8656-fd27-471a-a4e0-281bcc87440e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now compute all the metrics for the mean prediction, dice, avd, lesion f1 score.\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import scipy\n",
    "\n",
    "def getDSC(testImage, resultImage):    \n",
    "        \"\"\"Compute the Dice Similarity Coefficient.\"\"\"\n",
    "        # testArray   = sitk.GetArrayFromImage(testImage).flatten()\n",
    "        # resultArray = sitk.GetArrayFromImage(resultImage).flatten()\n",
    "        testArray = testImage.reshape(-1).cpu().numpy()\n",
    "        resultArray = resultImage.reshape(-1).cpu().numpy()\n",
    "\n",
    "        # similarity = 1.0 - dissimilarity\n",
    "        return 1.0 - scipy.spatial.distance.dice(testArray, resultArray) \n",
    "\n",
    "def getLesionDetection(testImage, resultImage):    \n",
    "    \"\"\"Lesion detection metrics, both recall and F1.\"\"\"\n",
    "    testImage = sitk.GetImageFromArray(testImage)\n",
    "    resultImage = sitk.GetImageFromArray(resultImage)\n",
    "\n",
    "    # Connected components will give the background label 0, so subtract 1 from all results\n",
    "    ccFilter = sitk.ConnectedComponentImageFilter()    \n",
    "    ccFilter.SetFullyConnected(True)\n",
    "\n",
    "    # Connected components on the test image, to determine the number of true WMH.\n",
    "    # And to get the overlap between detected voxels and true WMH\n",
    "    ccTest = ccFilter.Execute(testImage)    \n",
    "    lResult = sitk.Multiply(ccTest, sitk.Cast(resultImage, sitk.sitkUInt32))\n",
    "\n",
    "    ccTestArray = sitk.GetArrayFromImage(ccTest)\n",
    "    lResultArray = sitk.GetArrayFromImage(lResult)\n",
    "\n",
    "    # recall = (number of detected WMH) / (number of true WMH) \n",
    "    nWMH = len(np.unique(ccTestArray)) - 1\n",
    "    if nWMH == 0:\n",
    "        recall = 1.0\n",
    "    else:\n",
    "        recall = float(len(np.unique(lResultArray)) - 1) / nWMH\n",
    "\n",
    "    # Connected components of results, to determine number of detected lesions\n",
    "    ccResult = ccFilter.Execute(resultImage)\n",
    "    lTest = sitk.Multiply(ccResult, sitk.Cast(testImage, sitk.sitkUInt32))\n",
    "\n",
    "    ccResultArray = sitk.GetArrayFromImage(ccResult)\n",
    "    lTestArray = sitk.GetArrayFromImage(lTest)\n",
    "\n",
    "    # precision = (number of detections that intersect with WMH) / (number of all detections)\n",
    "    nDetections = len(np.unique(ccResultArray)) - 1\n",
    "    if nDetections == 0:\n",
    "        precision = 1.0\n",
    "    else:\n",
    "        precision = float(len(np.unique(lTestArray)) - 1) / nDetections\n",
    "\n",
    "    if precision + recall == 0.0:\n",
    "        f1 = 0.0\n",
    "    else:\n",
    "        f1 = 2.0 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    return recall, f1    \n",
    "\n",
    "\n",
    "def getAVD(testImage, resultImage):   \n",
    "    \"\"\"Volume statistics.\"\"\"\n",
    "    testImage = sitk.GetImageFromArray(testImage)\n",
    "    resultImage = sitk.GetImageFromArray(resultImage)\n",
    "\n",
    "    # Compute statistics of both images\n",
    "    testStatistics   = sitk.StatisticsImageFilter()\n",
    "    resultStatistics = sitk.StatisticsImageFilter()\n",
    "\n",
    "    testStatistics.Execute(testImage)\n",
    "    resultStatistics.Execute(resultImage)\n",
    "\n",
    "    return float(abs(testStatistics.GetSum() - resultStatistics.GetSum())) / float(testStatistics.GetSum()) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41efffc5-a137-4f0a-957a-27e9b2a8e8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [02:02<00:00,  2.05it/s]\n"
     ]
    }
   ],
   "source": [
    "dices = []\n",
    "avds = []\n",
    "f1s = []\n",
    "recalls = []\n",
    "for i in tqdm(range(len(means)), position=0, leave=True):\n",
    "    pred = means[i].argmax(dim=1)\n",
    "    target = test_datasets[i][1][0].type(torch.int64)\n",
    "    dices.append(getDSC(target, pred))\n",
    "    avds.append(getAVD(target.numpy(), pred.numpy()))\n",
    "    recall, f1 = getLesionDetection(target.numpy(), pred.numpy())\n",
    "    recalls.append(recall)\n",
    "    f1s.append(f1)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7e66973-fec3-42d3-b33d-436474633d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|████████████▊                                                                                                                                           | 21/250 [00:56<10:38,  2.79s/it]/home/s2208943/miniconda3/envs/uq/lib/python3.10/site-packages/numpy/lib/function_base.py:4573: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [12:10<00:00,  2.92s/it]\n"
     ]
    }
   ],
   "source": [
    "### recording the sample diversity of volumes. (I can get range, IQR, coefficient of variation, skewness)\n",
    "results = []\n",
    "for i, s in tqdm(enumerate(samples), position=0, leave=True, total=len(samples)):\n",
    "    s_pred = s.cuda().argmax(dim=2)\n",
    "    slices = s.shape[1]\n",
    "    num_samples = s.shape[0]\n",
    "    s_pred = s.argmax(dim=2)\n",
    "    slice_vols = s_pred.sum(dim=(-2, -1))\n",
    "    sorted_slice_vols = torch.sort(slice_vols, dim=0)[1]\n",
    "    sorted_samples = torch.zeros(s_pred.shape)\n",
    "    for j in range(num_samples):\n",
    "        sorted_samples[j] = s_pred[sorted_slice_vols[j], torch.arange(0, slices, 1)]\n",
    "    sorted_sample_volumes = sorted_samples.sum(dim=(-3, -2, -1)).cpu()\n",
    "    \n",
    "    assert torch.equal(sorted_sample_volumes, torch.sort(sorted_sample_volumes)[0])\n",
    "    \n",
    "    mean_vol = means[i].cuda().argmax(dim=1).sum(dim=(-3, -2, -1)).item()\n",
    "    \n",
    "    ss_vds = ((sorted_sample_volumes - mean_vol).abs() / mean_vol) * 100\n",
    "    \n",
    "    results.append([\n",
    "        sorted_sample_volumes.std().item(),\n",
    "        scipy.stats.iqr(sorted_sample_volumes),\n",
    "        scipy.stats.skew(sorted_sample_volumes),\n",
    "        \n",
    "        ss_vds.std().item(),\n",
    "        scipy.stats.iqr(ss_vds),\n",
    "        scipy.stats.skew(ss_vds),\n",
    "        \n",
    "    ])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd2c0488-e414-47cc-8ade-a82a2ef6ddb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = {\n",
    "    \"ID\":IDs,\n",
    "    \"dice\":dices,\n",
    "    \"f1\":f1s,\n",
    "    \"avd\":avds,\n",
    "    \"recall\":recall,\n",
    "    \"sample_div_std\":[r[0] for r in results],\n",
    "    \"sample_div_IQR\":[r[1] for r in results],\n",
    "    \"sample_div_skew\":[r[2] for r in results],\n",
    "    \"sample_div_vd_std\":[r[3] for r in results],\n",
    "    \"sample_div_vd_IQR\":[r[4] for r in results],\n",
    "    \"sample_div_vd_skew\":[r[5] for r in results],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(df)\n",
    "df.to_csv(\"umap_data_spreadsheets/CVD/CHAL_BASED_sample_div_data_SSN_Ens.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc879d52-1eff-4403-bc91-f283667eaf9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
