{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f64cd201-3332-41bd-bf9a-f9e72526f963",
   "metadata": {},
   "source": [
    "### Load Model Samples\n",
    "save dice:\n",
    "dice is based on SSN Ens Mean I think? or SSN Ens? I am not sure....?\n",
    "sample diversity definately comes from SSN Ens.\n",
    "I am not sure how much memory I need for this aha\n",
    "Sample diversity should be based on AVD and I should check the mean dice against what I have reported in my paper (it should be similar, probs won't be exactly the same)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6aa71d21-3a35-4705-9d97-2718edcd5701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strawberry\n",
      "banana\n"
     ]
    }
   ],
   "source": [
    "print(\"strawberry\")\n",
    "\n",
    "# loss function and metrics\n",
    "from trustworthai.utils.losses_and_metrics.dice_loss import DiceLossWithWeightedEmptySlices\n",
    "from trustworthai.utils.losses_and_metrics.dice_loss_metric import DiceLossMetric, SsnDiceMeanMetricWrapper\n",
    "\n",
    "# predefined training dataset\n",
    "from trustworthai.utils.data_preprep.dataset_pipelines import load_data\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "# fitter\n",
    "from trustworthai.utils.fitting_and_inference.fitters.basic_lightning_fitter import StandardLitModelWrapper\n",
    "from trustworthai.utils.fitting_and_inference.fitters.p_unet_fitter import PUNetLitModelWrapper\n",
    "from trustworthai.utils.fitting_and_inference.get_trainer import get_trainer\n",
    "\n",
    "# model\n",
    "from trustworthai.run.model_load.load_ssn import load_ssn\n",
    "from trustworthai.run.model_load.load_punet import load_p_unet\n",
    "from trustworthai.run.model_load.load_deterministic import load_deterministic\n",
    "from trustworthai.models.stochastic_wrappers.ssn.LowRankMVCustom import LowRankMultivariateNormalCustom\n",
    "from trustworthai.models.stochastic_wrappers.ssn.ReshapedDistribution import ReshapedDistribution\n",
    "\n",
    "# optimizer and lr scheduler\n",
    "import torch\n",
    "\n",
    "# misc\n",
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import shlex\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "from natsort import natsorted\n",
    "\n",
    "print(\"banana\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3561b57-8ba3-4fbc-b5f1-374837faa575",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trustworthai.utils.data_preprep.dataset_pipelines import load_clinscores_data, load_data, ClinScoreDataRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a1343b8-a9a8-40ac-a68b-f895588c9a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_folder = \"/home/s2208943/ipdis/results/cross_validated_models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75c3060c-304f-4a17-98cc-7e9c4b19282e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_parser():\n",
    "    parser = argparse.ArgumentParser(description = \"train models\")\n",
    "    \n",
    "    # folder arguments\n",
    "    parser.add_argument('--ckpt_dir', default='s2208943/results/revamped_models/', type=str)\n",
    "    parser.add_argument('--model_name', default=None, type=str)\n",
    "    \n",
    "    # data generation arguments\n",
    "    parser.add_argument('--dataset', default='ed', type=str)\n",
    "    parser.add_argument('--seed', default=3407, type=int)\n",
    "    parser.add_argument('--test_split', default=0.15, type=float)\n",
    "    parser.add_argument('--val_split', default=0.15, type=float)\n",
    "    parser.add_argument('--empty_slice_retention', default=0.1, type=float)\n",
    "    \n",
    "    # model specific parameters SSN\n",
    "    parser.add_argument('--ssn_rank', default=15, type=int)\n",
    "    parser.add_argument('--ssn_epsilon', default=1e-5, type=float)\n",
    "    parser.add_argument('--ssn_mc_samples', default=10, type=int)\n",
    "    parser.add_argument('--ssn_sample_dice_coeff', default=0.05, type=float)\n",
    "    parser.add_argument('--ssn_pre_head_layers', default=16, type=int)\n",
    "    \n",
    "    # evidential loss parameters\n",
    "    parser.add_argument('--kl_factor', default=0.1, type=float)\n",
    "    parser.add_argument('--kl_anneal_count', default=452*4, type=int)\n",
    "    \n",
    "     # model specific parameters Punet\n",
    "    parser.add_argument('--kl_beta', default=10.0, type=float)\n",
    "    parser.add_argument('--use_prior_for_dice', default=False, type=bool)\n",
    "    parser.add_argument('--punet_sample_dice_coeff', default=0.05, type=float)\n",
    "    parser.add_argument('--latent_dim', default=12, type=int)\n",
    "    \n",
    "    # general arguments for the loss function\n",
    "    parser.add_argument('--dice_factor', default=5, type=float)\n",
    "    parser.add_argument('--xent_factor', default=0.01, type=float)\n",
    "    parser.add_argument('--dice_empty_slice_weight', default=0.5, type=float)\n",
    "    \n",
    "    # general arguments for the loss function\n",
    "    parser.add_argument('--loss_name', default='dice+xent', type=str)\n",
    "    # parser.add_argument('--dice_factor', default=5, type=float)\n",
    "    # parser.add_argument('--xent_factor', default=0.01, type=float)\n",
    "    parser.add_argument('--xent_weight', default='none', type=str)\n",
    "    #parser.add_argument('--dice_empty_slice_weight', default=0.5, type=float)\n",
    "    parser.add_argument('--tversky_beta', default=0.7, type=float)\n",
    "    parser.add_argument('--reduction', default='mean_sum', type=str)\n",
    "    \n",
    "    # training paradigm arguments\n",
    "    parser.add_argument('--lr', default=2e-4, type=float)\n",
    "    parser.add_argument('--dropout_p', default=0.0, type=float)\n",
    "    parser.add_argument('--max_epochs', default=100, type=int)\n",
    "    parser.add_argument('--early_stop_patience', default=15, type=int)\n",
    "    parser.add_argument('--batch_size', default=32, type=int)\n",
    "    parser.add_argument('--cross_validate', default=False, type=bool)\n",
    "    parser.add_argument('--cv_split', default=0, type=int)\n",
    "    parser.add_argument('--cv_test_fold_smooth', default=1, type=int)\n",
    "    parser.add_argument('--weight_decay', default=0.0001, type=float)\n",
    "    parser.add_argument('--overwrite', default=False, type=bool)\n",
    "    \n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4adbac25-a469-4bb1-9eb5-7095d1d03c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_best_checkpoint(model, loss, model_ckpt_folder, punet=False):\n",
    "    # this is ultimately going to need to be passed a model wrapper when I implement P-Unet....\n",
    "    \n",
    "    # the path to the best checkpoint is stored as a single line in a txt file along with each model\n",
    "    with open(os.path.join(model_ckpt_folder, \"best_ckpt.txt\"), \"r\") as f:\n",
    "        ckpt_file = os.path.join(model_ckpt_folder, f.readlines()[0][:-1].split(\"/\")[-1])\n",
    "    \n",
    "    if punet:\n",
    "        return PUNetLitModelWrapper.load_from_checkpoint(ckpt_file, model=model, loss=loss, \n",
    "                                    logging_metric=lambda : None)\n",
    "    return StandardLitModelWrapper.load_from_checkpoint(ckpt_file, model=model, loss=loss, \n",
    "                                    logging_metric=lambda : None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0baae5f6-42bf-4a39-aaf5-8cac2d7a9210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_map_from_mean(mean, do_normalize=True):\n",
    "    \"samples is of shape samples, batch size, channels, image dims  [s, b, c *<dims>]\"\n",
    "    if mean.shape[1] == 1:\n",
    "        raise ValueError(\"not implemented for implicit background class\")\n",
    "    else:\n",
    "        assert mean.shape[1] == 2\n",
    "    \n",
    "    if do_normalize:\n",
    "        probs = torch.nn.functional.softmax(mean, dim=1)\n",
    "    else:\n",
    "        probs = mean\n",
    "    ent_map = torch.sum(-probs * torch.log(probs+1e-30), dim=1)\n",
    "\n",
    "    return ent_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "598f5d3b-2b60-4ce6-8918-f0d706b46631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_means_and_samples_SSN(splits=6, dataset_stride=2, temp=1, num_samples=10, use_updated_scores=False):\n",
    "    # load data\n",
    "    clin_retriever = ClinScoreDataRetriever(use_updated_scores=use_updated_scores)\n",
    "    \n",
    "    rank = 15\n",
    "    \n",
    "    # load model\n",
    "    class TestArgs():\n",
    "        def __init__(self, ):\n",
    "            args_dict = {\n",
    "                \"dropout_p\":0,\n",
    "                \"ssn_pre_head_layers\":32,\n",
    "                \"ssn_rank\":rank,\n",
    "                \"ssn_epsilon\":1e-5,\n",
    "                \"dice_empty_slice_weight\":0.5,\n",
    "                \"ssn_mc_samples\":10,\n",
    "                \"dice_factor\":5,\n",
    "                \"xent_factor\":0.01,\n",
    "                \"ssn_sample_dice_coeff\":0.05\n",
    "            }\n",
    "\n",
    "            for key, value in args_dict.items():\n",
    "                setattr(self, key, value)\n",
    "\n",
    "    args = TestArgs()\n",
    "\n",
    "    model_raw, loss = load_ssn(args)\n",
    "    model_raw = model_raw.cuda()\n",
    "    \n",
    "    models_folder = \"/home/s2208943/ipdis/results/cross_validated_models/\"\n",
    "    #model_names = os.listdir(models_folder)\n",
    "\n",
    "    model_base_name = \"ssn_WMH_chal\"\n",
    "    ensemble_element = 1\n",
    "\n",
    "    means = []\n",
    "    samples = []\n",
    "\n",
    "    test_datasets = []\n",
    "\n",
    "    for split in range(splits):\n",
    "        \n",
    "        # load specific data split\n",
    "        train_ds_clin, val_ds_clin, test_ds_clin = clin_retriever.load_clinscores_data(\n",
    "            combine_all=False,\n",
    "            test_proportion=0.15, \n",
    "            validation_proportion=0.15,\n",
    "            seed=3407,\n",
    "            cross_validate=True,\n",
    "            cv_split=split,\n",
    "            cv_test_fold_smooth=1,\n",
    "            \n",
    "        )\n",
    "        test_datasets.append(test_ds_clin)\n",
    "        print(\"size: \", len(test_ds_clin))\n",
    "\n",
    "\n",
    "        for ens in range(1):\n",
    "            model_name = model_base_name + f\"_ens{ensemble_element}/\"\n",
    "            model_path = models_folder + model_name\n",
    "\n",
    "            model = load_best_checkpoint(model_raw, loss, model_path)\n",
    "            model.eval()\n",
    "\n",
    "\n",
    "            dataskip = dataset_stride\n",
    "            \n",
    "        for i, data in enumerate(tqdm(test_ds_clin, position=0, leave=True)):\n",
    "            if i % dataskip == 0:\n",
    "                x = data[0]\n",
    "                with torch.no_grad():\n",
    "                    mean, sample = model.mean_and_sample(x.swapaxes(0,1).cuda(), num_samples=num_samples, temperature=temp)\n",
    "                    means.append(mean.cpu())\n",
    "                    samples.append(sample.cpu())\n",
    "\n",
    "    return means, samples, ConcatDataset(test_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd1a7915-2419-4737-85bf-f8f4da925f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_means_and_samples_SSN_Ens_Efficient(splits=6, dataset_stride=2, temp=1, num_samples=10, use_updated_scores=False, ensemble_size=6):\n",
    "    # load data\n",
    "    clin_retriever = ClinScoreDataRetriever(use_updated_scores=use_updated_scores)\n",
    "    \n",
    "    # load model\n",
    "    class TestArgs():\n",
    "        def __init__(self, ):\n",
    "            args_dict = {\n",
    "                \"dropout_p\":0,\n",
    "                \"ssn_pre_head_layers\":32,\n",
    "                \"ssn_rank\":15,\n",
    "                \"ssn_epsilon\":1e-5,\n",
    "                \"dice_empty_slice_weight\":0.5,\n",
    "                \"ssn_mc_samples\":10,\n",
    "                \"dice_factor\":5,\n",
    "                \"xent_factor\":0.01,\n",
    "                \"ssn_sample_dice_coeff\":0.05\n",
    "            }\n",
    "\n",
    "            for key, value in args_dict.items():\n",
    "                setattr(self, key, value)\n",
    "\n",
    "    args = TestArgs()\n",
    "\n",
    "    model_raw, loss = load_ssn(args)\n",
    "    model_raw = model_raw.cuda()\n",
    "    \n",
    "    models_folder = \"/home/s2208943/ipdis/results/cross_validated_models/\"\n",
    "    #model_names = os.listdir(models_folder)\n",
    "\n",
    "    model_base_name = \"ssn_WMH_chal\"\n",
    "\n",
    "    means = []\n",
    "    samples = []\n",
    "\n",
    "    test_datasets = []\n",
    "\n",
    "    for split in range(splits):\n",
    "        model_outs = defaultdict(lambda : {'means':[], 'samples':[]})\n",
    "        \n",
    "        # load specific data split\n",
    "        train_ds_clin, val_ds_clin, test_ds_clin = clin_retriever.load_clinscores_data(\n",
    "            combine_all=False,\n",
    "            test_proportion=0.15, \n",
    "            validation_proportion=0.15,\n",
    "            seed=3407,\n",
    "            cross_validate=True,\n",
    "            cv_split=split,\n",
    "            cv_test_fold_smooth=1,\n",
    "            \n",
    "        )\n",
    "        test_datasets.append(test_ds_clin)\n",
    "        print(\"size: \", len(test_ds_clin))\n",
    "\n",
    "\n",
    "        for ens in range(ensemble_size):\n",
    "            model_name = model_base_name + f\"_ens{ens}/\"\n",
    "            model_path = models_folder + model_name\n",
    "\n",
    "            # with open(model_path + \"best_ckpt.txt\") as f:\n",
    "            #     lines = f.readlines()\n",
    "            #     args_lines = [l[:-1].split(\": \") for l in lines[1:]]\n",
    "            #     args_lines = [f'--{l[0]} {l[1]}' for l in args_lines]\n",
    "            #     args_line = \" \".join(args_lines)\n",
    "            #     parser = construct_parser()\n",
    "            #     args = parser.parse_args(shlex.split(args_line))\n",
    "\n",
    "            # load the model\n",
    "            model = load_best_checkpoint(model_raw, loss, model_path)\n",
    "            model.eval()\n",
    "\n",
    "\n",
    "            dataskip = dataset_stride\n",
    "            # means = []\n",
    "            # samples = []\n",
    "            for i, data in enumerate(tqdm(test_ds_clin, position=0, leave=True)):\n",
    "                if i % dataskip == 0:\n",
    "                    x = data[0]\n",
    "                    with torch.no_grad():\n",
    "                        mean, sample = model.mean_and_sample(x.swapaxes(0,1).cuda(), num_samples=num_samples, temperature=temp, symmetric=False)\n",
    "\n",
    "                        model_outs[i]['means'].append(mean.cpu())\n",
    "                        model_outs[i]['samples'].append(sample.cpu())\n",
    "\n",
    "        for idx in tqdm(model_outs.keys(), position=0, leave=True):\n",
    "            means.append(torch.stack(model_outs[idx]['means'], dim=0).mean(dim=0))\n",
    "            samples.append(torch.cat(model_outs[idx]['samples'], dim=0))\n",
    "\n",
    "    return means, samples, ConcatDataset(test_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd45e6b9-9ad2-4c56-9282-9fee523fdacf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_means_and_samples_SSN_Ens_Mean(splits=6, dataset_stride=2, temp=1, num_samples=10, use_updated_scores=False, ensemble_size=6):\n",
    "    components = ensemble_size\n",
    "    # load data\n",
    "    print(\"loading\")\n",
    "    clin_retriever = ClinScoreDataRetriever(use_updated_scores=use_updated_scores)\n",
    "    print(\"loaded\")\n",
    "    \n",
    "    test_datasets = []\n",
    "\n",
    "    # load model\n",
    "    class TestArgs():\n",
    "        def __init__(self, ):\n",
    "            args_dict = {\n",
    "                \"dropout_p\":0,\n",
    "                \"ssn_pre_head_layers\":32,\n",
    "                \"ssn_rank\":15,\n",
    "                \"ssn_epsilon\":1e-5,\n",
    "                \"dice_empty_slice_weight\":0.5,\n",
    "                \"ssn_mc_samples\":10,\n",
    "                \"dice_factor\":5,\n",
    "                \"xent_factor\":0.01,\n",
    "                \"ssn_sample_dice_coeff\":0.05\n",
    "            }\n",
    "\n",
    "            for key, value in args_dict.items():\n",
    "                setattr(self, key, value)\n",
    "\n",
    "    args = TestArgs()\n",
    "\n",
    "    model_raw, loss = load_ssn(args)\n",
    "    model_raw = model_raw.cuda()\n",
    "    model_raw.return_cpu_dist = True\n",
    "\n",
    "    models_folder = \"/home/s2208943/ipdis/results/cross_validated_models/\"\n",
    "    #model_names = os.listdir(models_folder)\n",
    "\n",
    "    model_base_name = \"ssn_WMH_chal\"\n",
    "\n",
    "    means = []\n",
    "    samples = []\n",
    "\n",
    "    for split in range(splits):\n",
    "        # load specific data split\n",
    "        train_ds_clin, val_ds_clin, test_ds_clin = clin_retriever.load_clinscores_data(\n",
    "            combine_all=False,\n",
    "            test_proportion=0.15, \n",
    "            validation_proportion=0.12,\n",
    "            seed=3407,\n",
    "            cross_validate=True,\n",
    "            cv_split=split,\n",
    "            cv_test_fold_smooth=1,\n",
    "        )\n",
    "        test_datasets.append(test_ds_clin)\n",
    "        # print(\"size: \", len(test_ds_clin))\n",
    "\n",
    "        dataskip = dataset_stride\n",
    "\n",
    "        for i, data in enumerate(tqdm(test_ds_clin, position=0, leave=True)):\n",
    "            if i % dataskip == 0:\n",
    "                x = data[0].swapaxes(0,1).cuda()\n",
    "                distribution_means = []\n",
    "                distribution_cov_diags = []\n",
    "                distribution_cov_factors = []\n",
    "                distribution_event_shapes = []\n",
    "\n",
    "                for ens in range(components):\n",
    "                    # print(ens)\n",
    "                    model_name = model_base_name + f\"_ens{ens}/\"\n",
    "                    model_path = models_folder + model_name\n",
    "                    model = load_best_checkpoint(model_raw, loss, model_path)\n",
    "                    model.eval()\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        mean, cov_diag, cov_factor, event_shape = model(x)\n",
    "                    distribution_means.append(mean.cpu())\n",
    "                    distribution_cov_diags.append(cov_diag.cpu())\n",
    "                    distribution_cov_factors.append(cov_factor.cpu())\n",
    "                    distribution_event_shapes.append(event_shape)\n",
    "\n",
    "                # print(distribution_means[0].shape)\n",
    "\n",
    "                distribution_means = torch.stack(distribution_means, dim=0).mean(dim=0)\n",
    "                distribution_cov_diags = torch.stack(distribution_cov_diags, dim=0).mean(dim=0)\n",
    "                distribution_cov_factors = torch.stack(distribution_cov_factors, dim=0).mean(dim=0)\n",
    "\n",
    "                # print(distribution_means.shape)\n",
    "\n",
    "                dist = LowRankMultivariateNormalCustom(distribution_means, distribution_cov_factors, distribution_cov_diags)\n",
    "                dist = ReshapedDistribution(dist, distribution_event_shapes[0])\n",
    "\n",
    "                means.append((dist.mean / temp).cpu())\n",
    "                samples.append((model_raw._samples_from_dist(dist, num_samples=num_samples)/temp).cpu())\n",
    "\n",
    "    return means, samples, ConcatDataset(test_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4731c404-dce9-46b9-a4c5-f93f90d6a230",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from trustworthai.utils.uncertainty_maps.entropy_map import entropy_map_from_samples\n",
    "from trustworthai.utils.plotting.saving_plots import save, imsave\n",
    "from trustworthai.utils.print_and_write_func import print_and_write\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d84d4b30-19af-4747-9d9b-8359b42f089f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#samples[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1aa8527-7263-4c05-8505-215f7a7b468d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stride = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f879a8e-40da-46d2-a73d-58aad39c2d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading\n",
      "loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [05:20<00:00,  7.62s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [05:06<00:00,  7.30s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [05:08<00:00,  7.34s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [05:16<00:00,  7.54s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [05:15<00:00,  7.52s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [04:43<00:00,  7.08s/it]\n"
     ]
    }
   ],
   "source": [
    "# means, samples, test_datasets = generate_means_and_samples_SSN(splits=6, dataset_stride=stride, temp=1, num_samples=10)\n",
    "# means, samples, test_datasets = generate_means_and_samples_SSN_Ens_Efficient(splits=6, dataset_stride=stride, temp=1, num_samples=2, use_updated_scores=False)\n",
    "means, samples, test_datasets = generate_means_and_samples_SSN_Ens_Mean(splits=6, dataset_stride=stride, temp=1, num_samples=10, use_updated_scores=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd26c099-11c4-46d1-94f7-c8a2eb68e8bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 250)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(means), len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fb9188-d9bb-43e1-b631-bb175f7951ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff10b600-671d-4b56-8b7e-1266b4b64281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (DatabaseError('database disk image is malformed')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "# softmax entropy\n",
    "# ent_maps = [entropy_map_from_mean(means[scan_index], do_normalize=True) for scan_index in range(len(means))]\n",
    "\n",
    "# evidential\n",
    "# ent_maps = [entropy_map_from_mean(means[scan_index], do_normalize=False) for scan_index in range(len(means))]\n",
    "\n",
    "# other methods\n",
    "ent_maps = [entropy_map_from_samples(samples[scan_index]) for scan_index in range(len(means))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8e0afe9-aa93-4432-bd4c-f51c3db91279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 159.5, 223.5, -0.5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scan_id = 0\n",
    "islice = 20\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(ent_maps[scan_id][islice]); plt.axis('off')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(means[scan_id][islice].argmax(dim=0)); plt.axis('off')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(test_datasets[scan_id][1][0][islice]); plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87c03edf-4939-49ae-826b-e9276d4e9c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_dice(pred, target):\n",
    "    p1 = (pred == 1)\n",
    "    t1 = (target == 1)\n",
    "    intersection = (pred == 1) & (target == 1)\n",
    "    numerator = 2 * intersection.sum()\n",
    "    denominator = p1.sum() + t1.sum()\n",
    "    return (numerator/(denominator + 1e-30)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b3079d0-fac7-4b03-aaf0-b9557dd17906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 2, 224, 160])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4f05076-ae8a-444f-8e9f-87ae7e064f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:39<00:00,  6.29it/s]\n"
     ]
    }
   ],
   "source": [
    "dices = []\n",
    "for i in tqdm(range(len(means)), position=0, leave=True):\n",
    "    pred = means[i].cuda().argmax(dim=1)\n",
    "    target = test_datasets[i][1][0].cuda()\n",
    "    dices.append(fast_dice(pred, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34eec10b-8347-4aee-957d-497968e3a50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_dices = [d for d in dices if d > 0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da9dc4c9-eb6c-40d1-a765-0d8e4283ce80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5605)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(f_dices).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb6c5a1e-288e-4f84-9d73-6a214678d573",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDs = [data[2]['ID'] for data in test_datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13bc8656-fd27-471a-a4e0-281bcc87440e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now compute all the metrics for the mean prediction, dice, avd, lesion f1 score.\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import scipy\n",
    "\n",
    "def getDSC(testImage, resultImage):    \n",
    "        \"\"\"Compute the Dice Similarity Coefficient.\"\"\"\n",
    "        # testArray   = sitk.GetArrayFromImage(testImage).flatten()\n",
    "        # resultArray = sitk.GetArrayFromImage(resultImage).flatten()\n",
    "        testArray = testImage.reshape(-1).cpu().numpy()\n",
    "        resultArray = resultImage.reshape(-1).cpu().numpy()\n",
    "\n",
    "        # similarity = 1.0 - dissimilarity\n",
    "        return 1.0 - scipy.spatial.distance.dice(testArray, resultArray) \n",
    "\n",
    "def getLesionDetection(testImage, resultImage):    \n",
    "    \"\"\"Lesion detection metrics, both recall and F1.\"\"\"\n",
    "    testImage = sitk.GetImageFromArray(testImage)\n",
    "    resultImage = sitk.GetImageFromArray(resultImage)\n",
    "\n",
    "    # Connected components will give the background label 0, so subtract 1 from all results\n",
    "    ccFilter = sitk.ConnectedComponentImageFilter()    \n",
    "    ccFilter.SetFullyConnected(True)\n",
    "\n",
    "    # Connected components on the test image, to determine the number of true WMH.\n",
    "    # And to get the overlap between detected voxels and true WMH\n",
    "    ccTest = ccFilter.Execute(testImage)    \n",
    "    lResult = sitk.Multiply(ccTest, sitk.Cast(resultImage, sitk.sitkUInt32))\n",
    "\n",
    "    ccTestArray = sitk.GetArrayFromImage(ccTest)\n",
    "    lResultArray = sitk.GetArrayFromImage(lResult)\n",
    "\n",
    "    # recall = (number of detected WMH) / (number of true WMH) \n",
    "    nWMH = len(np.unique(ccTestArray)) - 1\n",
    "    if nWMH == 0:\n",
    "        recall = 1.0\n",
    "    else:\n",
    "        recall = float(len(np.unique(lResultArray)) - 1) / nWMH\n",
    "\n",
    "    # Connected components of results, to determine number of detected lesions\n",
    "    ccResult = ccFilter.Execute(resultImage)\n",
    "    lTest = sitk.Multiply(ccResult, sitk.Cast(testImage, sitk.sitkUInt32))\n",
    "\n",
    "    ccResultArray = sitk.GetArrayFromImage(ccResult)\n",
    "    lTestArray = sitk.GetArrayFromImage(lTest)\n",
    "\n",
    "    # precision = (number of detections that intersect with WMH) / (number of all detections)\n",
    "    nDetections = len(np.unique(ccResultArray)) - 1\n",
    "    if nDetections == 0:\n",
    "        precision = 1.0\n",
    "    else:\n",
    "        precision = float(len(np.unique(lTestArray)) - 1) / nDetections\n",
    "\n",
    "    if precision + recall == 0.0:\n",
    "        f1 = 0.0\n",
    "    else:\n",
    "        f1 = 2.0 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    return recall, f1    \n",
    "\n",
    "\n",
    "def getAVD(testImage, resultImage):   \n",
    "    \"\"\"Volume statistics.\"\"\"\n",
    "    testImage = sitk.GetImageFromArray(testImage)\n",
    "    resultImage = sitk.GetImageFromArray(resultImage)\n",
    "\n",
    "    # Compute statistics of both images\n",
    "    testStatistics   = sitk.StatisticsImageFilter()\n",
    "    resultStatistics = sitk.StatisticsImageFilter()\n",
    "\n",
    "    testStatistics.Execute(testImage)\n",
    "    resultStatistics.Execute(resultImage)\n",
    "\n",
    "    return float(abs(testStatistics.GetSum() - resultStatistics.GetSum())) / float(testStatistics.GetSum()) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41efffc5-a137-4f0a-957a-27e9b2a8e8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [02:20<00:00,  1.78it/s]\n"
     ]
    }
   ],
   "source": [
    "dices = []\n",
    "avds = []\n",
    "f1s = []\n",
    "recalls = []\n",
    "for i in tqdm(range(len(means)), position=0, leave=True):\n",
    "    pred = means[i].argmax(dim=1)\n",
    "    target = test_datasets[i][1][0].type(torch.int64)\n",
    "    dices.append(getDSC(target, pred))\n",
    "    avds.append(getAVD(target.numpy(), pred.numpy()))\n",
    "    recall, f1 = getLesionDetection(target.numpy(), pred.numpy())\n",
    "    recalls.append(recall)\n",
    "    f1s.append(f1)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7e66973-fec3-42d3-b33d-436474633d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [12:16<00:00,  2.95s/it]\n"
     ]
    }
   ],
   "source": [
    "### recording the sample diversity of volumes. (I can get range, IQR, coefficient of variation, skewness)\n",
    "results = []\n",
    "for i, s in tqdm(enumerate(samples), position=0, leave=True, total=len(samples)):\n",
    "    s_pred = s.cuda().argmax(dim=2)\n",
    "    slices = s.shape[1]\n",
    "    num_samples = s.shape[0]\n",
    "    s_pred = s.argmax(dim=2)\n",
    "    slice_vols = s_pred.sum(dim=(-2, -1))\n",
    "    sorted_slice_vols = torch.sort(slice_vols, dim=0)[1]\n",
    "    sorted_samples = torch.zeros(s_pred.shape)\n",
    "    for j in range(num_samples):\n",
    "        sorted_samples[j] = s_pred[sorted_slice_vols[j], torch.arange(0, slices, 1)]\n",
    "    sorted_sample_volumes = sorted_samples.sum(dim=(-3, -2, -1)).cpu()\n",
    "    \n",
    "    assert torch.equal(sorted_sample_volumes, torch.sort(sorted_sample_volumes)[0])\n",
    "    \n",
    "    mean_vol = means[i].cuda().argmax(dim=1).sum(dim=(-3, -2, -1)).item()\n",
    "    \n",
    "    ss_vds = ((sorted_sample_volumes - mean_vol).abs() / mean_vol) * 100\n",
    "    \n",
    "    results.append([\n",
    "        sorted_sample_volumes.std().item(),\n",
    "        scipy.stats.iqr(sorted_sample_volumes),\n",
    "        scipy.stats.skew(sorted_sample_volumes),\n",
    "        \n",
    "        ss_vds.std().item(),\n",
    "        scipy.stats.iqr(ss_vds),\n",
    "        scipy.stats.skew(ss_vds),\n",
    "        \n",
    "    ])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd2c0488-e414-47cc-8ade-a82a2ef6ddb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = {\n",
    "    \"ID\":IDs,\n",
    "    \"dice\":dices,\n",
    "    \"f1\":f1s,\n",
    "    \"avd\":avds,\n",
    "    \"recall\":recall,\n",
    "    \"sample_div_std\":[r[0] for r in results],\n",
    "    \"sample_div_IQR\":[r[1] for r in results],\n",
    "    \"sample_div_skew\":[r[2] for r in results],\n",
    "    \"sample_div_vd_std\":[r[3] for r in results],\n",
    "    \"sample_div_vd_IQR\":[r[4] for r in results],\n",
    "    \"sample_div_vd_skew\":[r[5] for r in results],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(df)\n",
    "df.to_csv(\"umap_data_spreadsheets/CVD/CHAL_BASED_sample_div_data_SSN_Ens_Mean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bdd877-3a41-4049-b586-21c9fd4ef80f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
